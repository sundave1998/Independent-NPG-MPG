## **Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games**
[*Code for ''Provably Fast Convergence of Independent Natural Policy Gradient for Markov Potential Games'' (NeurIPS 2023)*](https://arxiv.org/abs/TBD)


### Prerequisites
Here we list our running environment:
- PyTorch == 1.10.0
- docplex == 2.18.200
- numpy == 1.19.2
- gym == 0.21.0
- matplotlib == 3.4.3
- mujoco == 2.2.2


### Tasks
We implement our proposed ARNPG algorithms in the following environments:
- Tabular MDP (oracle)
- Tabular MDP (sample-based)
- Acrobot-v1 (deep RL)
- Hopper-v3 (deep RL)


### Execution
To run the experiments, simply execute the following commands, where ''xxx'' corresponds to the name of files.
```
python xxx.py
```


